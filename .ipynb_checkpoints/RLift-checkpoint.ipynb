{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_KmVSVXeo8NS",
    "outputId": "cadec1a7-4364-4e50-dfb7-dd89c1cdc65e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mounted at /content/drive\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "RTRnm0v-_wjx"
   },
   "outputs": [],
   "source": [
    "!cp -r 'drive/MyDrive/x5_data' '.'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "IbeXj8GQfNh8",
    "outputId": "809823eb-7aa8-4664-feb1-dfb67305de36"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting scikit-uplift\n",
      "  Downloading https://files.pythonhosted.org/packages/ee/5e/67da3dad4edd74e8b532ce8ed9b127d21146e7c7fad3cd7fd4e3a3c45e00/scikit_uplift-0.3.1-py3-none-any.whl\n",
      "Requirement already satisfied: numpy>=1.16 in /usr/local/lib/python3.7/dist-packages (from scikit-uplift) (1.19.5)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from scikit-uplift) (2.23.0)\n",
      "Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from scikit-uplift) (1.1.5)\n",
      "Requirement already satisfied: scikit-learn>=0.21.0 in /usr/local/lib/python3.7/dist-packages (from scikit-uplift) (0.22.2.post1)\n",
      "Requirement already satisfied: matplotlib in /usr/local/lib/python3.7/dist-packages (from scikit-uplift) (3.2.2)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->scikit-uplift) (2.10)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->scikit-uplift) (1.24.3)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->scikit-uplift) (3.0.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->scikit-uplift) (2020.12.5)\n",
      "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.7/dist-packages (from pandas->scikit-uplift) (2018.9)\n",
      "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas->scikit-uplift) (2.8.1)\n",
      "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.21.0->scikit-uplift) (1.0.1)\n",
      "Requirement already satisfied: scipy>=0.17.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.21.0->scikit-uplift) (1.4.1)\n",
      "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->scikit-uplift) (2.4.7)\n",
      "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib->scikit-uplift) (0.10.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->scikit-uplift) (1.3.1)\n",
      "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.7.3->pandas->scikit-uplift) (1.15.0)\n",
      "Installing collected packages: scikit-uplift\n",
      "Successfully installed scikit-uplift-0.3.1\n",
      "Collecting causalml\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/44/ec/594b32198001b5babf79525958a4134dcbb44418b6296007aebe47024046/causalml-0.10.0.tar.gz (235kB)\n",
      "\u001b[K     |████████████████████████████████| 245kB 8.7MB/s \n",
      "\u001b[?25hRequirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.7/dist-packages (from causalml) (54.1.2)\n",
      "Requirement already satisfied: pip>=10.0 in /usr/local/lib/python3.7/dist-packages (from causalml) (19.3.1)\n",
      "Collecting numpy<1.19.0,>=0.16.0\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d6/c6/58e517e8b1fb192725cfa23c01c2e60e4e6699314ee9684a1c5f5c9b27e1/numpy-1.18.5-cp37-cp37m-manylinux1_x86_64.whl (20.1MB)\n",
      "\u001b[K     |████████████████████████████████| 20.1MB 442kB/s \n",
      "\u001b[?25hRequirement already satisfied: scipy==1.4.1 in /usr/local/lib/python3.7/dist-packages (from causalml) (1.4.1)\n",
      "Requirement already satisfied: matplotlib in /usr/local/lib/python3.7/dist-packages (from causalml) (3.2.2)\n",
      "Requirement already satisfied: pandas>=0.24.1 in /usr/local/lib/python3.7/dist-packages (from causalml) (1.1.5)\n",
      "Requirement already satisfied: scikit-learn<0.24.0,>=0.22.0 in /usr/local/lib/python3.7/dist-packages (from causalml) (0.22.2.post1)\n",
      "Requirement already satisfied: statsmodels>=0.9.0 in /usr/local/lib/python3.7/dist-packages (from causalml) (0.10.2)\n",
      "Requirement already satisfied: seaborn in /usr/local/lib/python3.7/dist-packages (from causalml) (0.11.1)\n",
      "Requirement already satisfied: Cython>=0.28.0 in /usr/local/lib/python3.7/dist-packages (from causalml) (0.29.22)\n",
      "Requirement already satisfied: xgboost in /usr/local/lib/python3.7/dist-packages (from causalml) (0.90)\n",
      "Requirement already satisfied: pydotplus in /usr/local/lib/python3.7/dist-packages (from causalml) (2.0.2)\n",
      "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from causalml) (4.41.1)\n",
      "Collecting shap<0.38.1\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/85/a3/c0eab9dd6a894165e2cb87504ff5b2710ac5ede3447d9138620b7341b6a2/shap-0.37.0.tar.gz (326kB)\n",
      "\u001b[K     |████████████████████████████████| 327kB 41.9MB/s \n",
      "\u001b[?25hRequirement already satisfied: dill in /usr/local/lib/python3.7/dist-packages (from causalml) (0.3.3)\n",
      "Requirement already satisfied: lightgbm in /usr/local/lib/python3.7/dist-packages (from causalml) (2.2.3)\n",
      "Collecting pygam\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/13/be/775033ef08a8945bec6ad7973b161ca909f852442e0d7cfb8d1a214de1ac/pygam-0.8.0-py2.py3-none-any.whl (1.8MB)\n",
      "\u001b[K     |████████████████████████████████| 1.8MB 46.2MB/s \n",
      "\u001b[?25hRequirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from causalml) (20.9)\n",
      "Requirement already satisfied: keras in /usr/local/lib/python3.7/dist-packages (from causalml) (2.4.3)\n",
      "Requirement already satisfied: tensorflow>=1.15.2 in /usr/local/lib/python3.7/dist-packages (from causalml) (2.4.1)\n",
      "Requirement already satisfied: torch in /usr/local/lib/python3.7/dist-packages (from causalml) (1.8.0+cu101)\n",
      "Collecting pyro-ppl\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/aa/7a/fbab572fd385154a0c07b0fa138683aa52e14603bb83d37b198e5f9269b1/pyro_ppl-1.6.0-py3-none-any.whl (634kB)\n",
      "\u001b[K     |████████████████████████████████| 634kB 45.4MB/s \n",
      "\u001b[?25hRequirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->causalml) (1.3.1)\n",
      "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib->causalml) (0.10.0)\n",
      "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->causalml) (2.4.7)\n",
      "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->causalml) (2.8.1)\n",
      "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.7/dist-packages (from pandas>=0.24.1->causalml) (2018.9)\n",
      "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn<0.24.0,>=0.22.0->causalml) (1.0.1)\n",
      "Requirement already satisfied: patsy>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from statsmodels>=0.9.0->causalml) (0.5.1)\n",
      "Collecting slicer==0.0.3\n",
      "  Downloading https://files.pythonhosted.org/packages/02/a6/c708c5a0f338e99cfbcb6288b88794525548e4fc1b8457feec2c552a81a4/slicer-0.0.3-py3-none-any.whl\n",
      "Requirement already satisfied: numba in /usr/local/lib/python3.7/dist-packages (from shap<0.38.1->causalml) (0.51.2)\n",
      "Requirement already satisfied: progressbar2 in /usr/local/lib/python3.7/dist-packages (from pygam->causalml) (3.38.0)\n",
      "Requirement already satisfied: future in /usr/local/lib/python3.7/dist-packages (from pygam->causalml) (0.16.0)\n",
      "Requirement already satisfied: h5py in /usr/local/lib/python3.7/dist-packages (from keras->causalml) (2.10.0)\n",
      "Requirement already satisfied: pyyaml in /usr/local/lib/python3.7/dist-packages (from keras->causalml) (3.13)\n",
      "Requirement already satisfied: grpcio~=1.32.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=1.15.2->causalml) (1.32.0)\n",
      "Requirement already satisfied: absl-py~=0.10 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=1.15.2->causalml) (0.10.0)\n",
      "Requirement already satisfied: typing-extensions~=3.7.4 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=1.15.2->causalml) (3.7.4.3)\n",
      "Requirement already satisfied: opt-einsum~=3.3.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=1.15.2->causalml) (3.3.0)\n",
      "Requirement already satisfied: google-pasta~=0.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=1.15.2->causalml) (0.2.0)\n",
      "Requirement already satisfied: termcolor~=1.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=1.15.2->causalml) (1.1.0)\n",
      "Requirement already satisfied: wrapt~=1.12.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=1.15.2->causalml) (1.12.1)\n",
      "Requirement already satisfied: astunparse~=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=1.15.2->causalml) (1.6.3)\n",
      "Requirement already satisfied: keras-preprocessing~=1.1.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=1.15.2->causalml) (1.1.2)\n",
      "Requirement already satisfied: six~=1.15.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=1.15.2->causalml) (1.15.0)\n",
      "Requirement already satisfied: tensorboard~=2.4 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=1.15.2->causalml) (2.4.1)\n",
      "Requirement already satisfied: gast==0.3.3 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=1.15.2->causalml) (0.3.3)\n",
      "Requirement already satisfied: tensorflow-estimator<2.5.0,>=2.4.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=1.15.2->causalml) (2.4.0)\n",
      "Requirement already satisfied: flatbuffers~=1.12.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=1.15.2->causalml) (1.12)\n",
      "Requirement already satisfied: protobuf>=3.9.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=1.15.2->causalml) (3.12.4)\n",
      "Requirement already satisfied: wheel~=0.35 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=1.15.2->causalml) (0.36.2)\n",
      "Collecting pyro-api>=0.1.1\n",
      "  Downloading https://files.pythonhosted.org/packages/fc/81/957ae78e6398460a7230b0eb9b8f1cb954c5e913e868e48d89324c68cec7/pyro_api-0.1.2-py3-none-any.whl\n",
      "Requirement already satisfied: llvmlite<0.35,>=0.34.0.dev0 in /usr/local/lib/python3.7/dist-packages (from numba->shap<0.38.1->causalml) (0.34.0)\n",
      "Requirement already satisfied: python-utils>=2.3.0 in /usr/local/lib/python3.7/dist-packages (from progressbar2->pygam->causalml) (2.5.6)\n",
      "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.4->tensorflow>=1.15.2->causalml) (1.8.0)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.4->tensorflow>=1.15.2->causalml) (3.3.4)\n",
      "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.4->tensorflow>=1.15.2->causalml) (0.4.3)\n",
      "Requirement already satisfied: google-auth<2,>=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.4->tensorflow>=1.15.2->causalml) (1.27.1)\n",
      "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.4->tensorflow>=1.15.2->causalml) (1.0.1)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.4->tensorflow>=1.15.2->causalml) (2.23.0)\n",
      "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard~=2.4->tensorflow>=1.15.2->causalml) (3.7.2)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.4->tensorflow>=1.15.2->causalml) (1.3.0)\n",
      "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard~=2.4->tensorflow>=1.15.2->causalml) (4.2.1)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard~=2.4->tensorflow>=1.15.2->causalml) (0.2.8)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4; python_version >= \"3.6\" in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard~=2.4->tensorflow>=1.15.2->causalml) (4.7.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.4->tensorflow>=1.15.2->causalml) (2020.12.5)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.4->tensorflow>=1.15.2->causalml) (1.24.3)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.4->tensorflow>=1.15.2->causalml) (2.10)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.4->tensorflow>=1.15.2->causalml) (3.0.4)\n",
      "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tensorboard~=2.4->tensorflow>=1.15.2->causalml) (3.4.1)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.4->tensorflow>=1.15.2->causalml) (3.1.0)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth<2,>=1.6.3->tensorboard~=2.4->tensorflow>=1.15.2->causalml) (0.4.8)\n",
      "Building wheels for collected packages: causalml, shap\n",
      "  Building wheel for causalml (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Created wheel for causalml: filename=causalml-0.10.0-cp37-cp37m-linux_x86_64.whl size=493678 sha256=6db6b952e8e8369733d4c38301c2ba4b81cb44b7d0b79a3256cb46993cdb5f0e\n",
      "  Stored in directory: /root/.cache/pip/wheels/81/7f/44/c9d5ecf03f0d950f53302a5eab1c76bec07bcd5868753e22bf\n",
      "  Building wheel for shap (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Created wheel for shap: filename=shap-0.37.0-cp37-cp37m-linux_x86_64.whl size=465041 sha256=21a1f3f9eea257c939c5c7e70425a1b32088660e359fea9dbc70fd97af9937b4\n",
      "  Stored in directory: /root/.cache/pip/wheels/df/ad/b0/aa7815ec68850d66551ef618095eccb962c8f6022f1d3dd989\n",
      "Successfully built causalml shap\n",
      "\u001b[31mERROR: tensorflow 2.4.1 has requirement numpy~=1.19.2, but you'll have numpy 1.18.5 which is incompatible.\u001b[0m\n",
      "\u001b[31mERROR: datascience 0.10.6 has requirement folium==0.2.1, but you'll have folium 0.8.3 which is incompatible.\u001b[0m\n",
      "\u001b[31mERROR: albumentations 0.1.12 has requirement imgaug<0.2.7,>=0.2.5, but you'll have imgaug 0.2.9 which is incompatible.\u001b[0m\n",
      "Installing collected packages: numpy, slicer, shap, pygam, pyro-api, pyro-ppl, causalml\n",
      "  Found existing installation: numpy 1.19.5\n",
      "    Uninstalling numpy-1.19.5:\n",
      "      Successfully uninstalled numpy-1.19.5\n",
      "Successfully installed causalml-0.10.0 numpy-1.18.5 pygam-0.8.0 pyro-api-0.1.2 pyro-ppl-1.6.0 shap-0.37.0 slicer-0.0.3\n"
     ]
    },
    {
     "data": {
      "application/vnd.colab-display-data+json": {
       "pip_warning": {
        "packages": [
         "numpy"
        ]
       }
      }
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "!pip install scikit-uplift\n",
    "!pip install causalml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "RHdGZsOU_aNk",
    "outputId": "b4e1cd4a-b07b-49e8-99bd-c00b4c5e6f5e"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/statsmodels/tools/_testing.py:19: FutureWarning: pandas.util.testing is deprecated. Use the functions in the public API at pandas.testing instead.\n",
      "  import pandas.util.testing as tm\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import copy\n",
    "from causalml.dataset import *\n",
    "\n",
    "y, X, treatment, tau, b, e = synthetic_data(mode=2, n=10000, p=8, sigma=1.0)\n",
    "X_train, X_test, y_train, y_test, treat_train, treat_test= train_test_split(X, y, treatment, test_size=0.33, random_state=0)\n",
    "train_idx, val_idx = train_test_split(np.arange(len(X_train)), test_size=0.3, random_state=123)\n",
    "X_val, y_val, treat_val = X_train[val_idx], y_train[val_idx], treat_train[val_idx]\n",
    "X_train, y_train, treat_train = X_train[train_idx], y_train[train_idx], treat_train[train_idx]\n",
    "\n",
    "action_probs = np.bincount(treat_train) / len(treat_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vPG6blLj_rr7"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch import nn\n",
    "\n",
    "class X5Dataset(Dataset):\n",
    "    def __init__(self, X, y, treat):\n",
    "        self.X = torch.from_numpy(X).type(torch.FloatTensor)\n",
    "        self.y = torch.from_numpy(y).type(torch.LongTensor)\n",
    "        self.treat = treat\n",
    "    \n",
    "    def __getitem__(self, id):\n",
    "        return self.X[id], self.y[id], self.treat[id]\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.X)\n",
    "\n",
    "def collate(batch):\n",
    "    X, y, treat = zip(*batch)\n",
    "    return X, y, treat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "51IIvhFjjkOU"
   },
   "outputs": [],
   "source": [
    "class PolicyGradient(nn.Module):\n",
    "        def __init__(self, n_action, n_features, hidden_dims):\n",
    "            super(PolicyGradient, self).__init__()\n",
    "\n",
    "            def get_dense_block(in_dim, out_dim):\n",
    "                return nn.Sequential(nn.Linear(in_dim, out_dim), nn.BatchNorm1d(out_dim), nn.Tanh())\n",
    "\n",
    "            blocks = [get_dense_block(n_features, hidden_dims[0])]\n",
    "            for i in range(len(hidden_dims) - 1):\n",
    "                blocks.append(get_dense_block(hidden_dims[i], hidden_dims[i + 1]))\n",
    "            self.net = nn.Sequential(*blocks,\n",
    "                                                                nn.Linear(hidden_dims[-1], n_action))\n",
    "\n",
    "        def forward(self, features):\n",
    "            return self.net(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wKSKqQ3Cj-IO"
   },
   "outputs": [],
   "source": [
    "class Trainer:\n",
    "    def __init__(self, model, action_probs, train_dataset, val_dataset, test_dataset, train_config, device, n_actions=2):\n",
    "        self.model = model\n",
    "        self.model.to(device)\n",
    "        self.train_loader = DataLoader(train_dataset, \n",
    "                                                                     batch_size=train_config.batch_size, \n",
    "                                                                     drop_last=True,\n",
    "                                                                     shuffle=True)\n",
    "        self.val_loader = DataLoader(val_dataset,\n",
    "                                                                 batch_size=train_config.batch_size)\n",
    "        self.test_loader = DataLoader(test_dataset,\n",
    "                                                                    batch_size=train_config.batch_size)\n",
    "        self.train_config = train_config\n",
    "        self.device = device\n",
    "        self.n_actions = 2\n",
    " \n",
    "        self.action_probs = action_probs\n",
    "\n",
    "        self.loss = nn.CrossEntropyLoss(reduce=False)\n",
    "        self.optimizer = torch.optim.Adam(model.parameters(), lr=train_config.lr)\n",
    "\n",
    "    def _SN_UMG(self, records, n_actions=2):\n",
    "        \"\"\"\n",
    "        records: a sequence of [algorithm_action, actual_action, y]\n",
    "        \"\"\"\n",
    "        response_numerator = 0\n",
    "        response_denominator = 0\n",
    "        control_numerator = np.zeros(n_actions)\n",
    "        control_denominator = np.zeros(n_actions)\n",
    "\n",
    "        for alg_a, act_a, y in records:\n",
    "            if alg_a == act_a:\n",
    "                response_numerator += y / self.action_probs[act_a]\n",
    "                response_denominator += 1 / self.action_probs[act_a]\n",
    "            if act_a == 0 and alg_a > 0:\n",
    "                control_numerator[alg_a] += y / self.action_probs[0]\n",
    "                control_denominator[alg_a] += 1 / self.action_probs[0]\n",
    "        \n",
    "        response = response_numerator / (response_denominator if response_denominator != 0 else 1)\n",
    "        action_control = control_numerator / np.where(control_denominator == 0, 1, control_denominator)\n",
    "\n",
    "        lift = response - control_numerator.sum() / (control_denominator.sum() if control_denominator.sum() != 0 else 1)\n",
    "\n",
    "        return lift, action_control\n",
    "\n",
    "    def _SN_UMG_GH(self, records, n_action=2):\n",
    "        n_treat = n_action - 1\n",
    "        real_prob = self.action_probs\n",
    "        algo_action_resp = {}\n",
    "        algo_total_norm = 0.0\n",
    "        algo_total_base_norm = 0.0\n",
    "        algo_treat_resp = [0.0] * n_treat\n",
    "        algo_total_resp = 0.0\n",
    "        algo_action_base = {}\n",
    "        algo_treat_base = [0.0] * n_treat\n",
    "        algo_total_base = 0.0\n",
    "        algo_treat_lift = [0.0] * n_treat\n",
    "        algo_total_lift = 0.0\n",
    "        algo_action_nums = np.array([0.0] * n_action)\n",
    "        algo_action_norm = np.array([0.0] * n_action)\n",
    "        algo_action_base_norm = np.array([0.0] * n_action)\n",
    "\n",
    "        real_action_resp = {}\n",
    "        real_treat_resp = [0.0] * n_treat\n",
    "        real_total_resp = 0.0\n",
    "        real_action_nums = np.array([0.0] * n_action)\n",
    "\n",
    "        for t in range(n_treat):\n",
    "                algo_action_resp[t] = np.array([0.0] * n_action)\n",
    "                algo_action_base[t] = np.array([0.0] * n_action)\n",
    "\n",
    "                real_action_resp[t] = np.array([0.0] * n_action)\n",
    "\n",
    "        for algo_action, real_action, resp in records:\n",
    "                algo_action_nums[algo_action] += 1\n",
    "                real_action_nums[real_action] += 1\n",
    "\n",
    "                algo_action_resp[0][algo_action] += resp * \\\n",
    "                        (real_action == algo_action) / real_prob[real_action]\n",
    "                algo_treat_resp[0] += resp * \\\n",
    "                        (real_action == algo_action) / real_prob[real_action]\n",
    "                algo_action_base[0][algo_action] += resp * \\\n",
    "                        (real_action == 0) / real_prob[0]\n",
    "                algo_treat_base[0] += resp * \\\n",
    "                        (real_action == 0) / real_prob[0]\n",
    "\n",
    "                real_action_resp[0][real_action] += resp\n",
    "                real_treat_resp += resp\n",
    "\n",
    "                algo_action_norm[algo_action] += (real_action == algo_action) * \\\n",
    "                        1.0 / real_prob[real_action]\n",
    "                algo_total_norm += (real_action == algo_action) / \\\n",
    "                        real_prob[real_action]\n",
    "                algo_action_base_norm[real_action] += (\n",
    "                        real_action == 0) * 1.0 / real_prob[real_action]\n",
    "                algo_total_base_norm += (real_action == 0) * \\\n",
    "                        1.0 / real_prob[real_action]\n",
    "\n",
    "        numSample = np.sum(algo_action_nums)\n",
    "\n",
    "        for a in range(n_action):\n",
    "                algo_action_resp[0][a] /= (algo_action_norm[a]\n",
    "                                                                        if algo_action_norm[a] > 0.0 else 1.0)\n",
    "                algo_action_base[0][a] /= (algo_action_norm[a]\n",
    "                                                                        if algo_action_norm[a] != 0.0 else 1.0)\n",
    "                real_action_resp[0][a] /= (real_action_nums[a]\n",
    "                                                                        if real_action_nums[a] != 0.0 else 1.0)\n",
    "        algo_treat_base[0] /= (algo_total_base_norm if algo_total_base_norm >\n",
    "                                                        0.0 else 1.0)\n",
    "        algo_treat_resp[0] /= (algo_total_norm if algo_total_norm >\n",
    "                                                        0.0 else 1.0)\n",
    "        real_treat_resp[0] /= numSample\n",
    "\n",
    "        algo_action_prob = algo_action_nums / np.sum(algo_action_nums)\n",
    "        real_action_prob = real_action_nums / np.sum(real_action_nums)\n",
    "\n",
    "        for i in range(n_treat):\n",
    "                for a in range(n_action):\n",
    "                        algo_treat_lift[i] += (algo_action_resp[i][a] -\n",
    "                                                                     algo_action_base[i][a]) * algo_action_prob[a]\n",
    "\n",
    "        for i in range(n_treat):\n",
    "                algo_total_lift += algo_treat_lift[i]\n",
    "                algo_total_resp += algo_treat_resp[i]\n",
    "                algo_total_base += algo_treat_base[i]\n",
    "\n",
    "                real_total_resp += real_treat_resp[i]\n",
    "\n",
    "        return algo_total_lift, algo_action_base\n",
    "            \n",
    "    def _get_train_metrics(self, set_of_records, n_actions=2):\n",
    "        lifts = []\n",
    "        action_controls = []\n",
    "        for records in set_of_records:\n",
    "            lift, action_control = self._SN_UMG_GH(records, n_action=n_actions)\n",
    "            lifts.append(lift)\n",
    "            action_controls.append(action_control[0])\n",
    "        \n",
    "        return lifts, np.mean(action_controls, axis=0)\n",
    "\n",
    "    def _train_epoch(self):\n",
    "        epoch_features = []\n",
    "        epoch_actions = []\n",
    "        epoch_rewards = []\n",
    "        epoch_treats = []\n",
    "        epoch_ys = []\n",
    "\n",
    "        preds = []\n",
    "        ys = []\n",
    "        treats = []\n",
    "\n",
    "        self.model.eval()\n",
    "        for X, y, treat in self.train_loader:\n",
    "            epoch_features.append(X)\n",
    "            X = X.to(device)\n",
    "\n",
    "            set_of_records = []\n",
    "            with torch.no_grad():\n",
    "                    logits = self.model(X)\n",
    "                    actions = torch.argmax(logits, 1)\n",
    "\n",
    "                    actions = actions.cpu().numpy()\n",
    "                    treat = treat.numpy()\n",
    "                    y = y.numpy()\n",
    "\n",
    "                    preds.extend(actions)\n",
    "                    treats.extend(treat)\n",
    "                    ys.extend(y)\n",
    "\n",
    "                    records = list(zip(actions, treat, y))\n",
    "                    set_of_records.append(records)\n",
    "                    \n",
    "                    epoch_ys.append(y)\n",
    "                    epoch_actions.append(actions)\n",
    "                    epoch_treats.append(treat)\n",
    "                        \n",
    "        lifts, action_control = self._get_train_metrics(set_of_records, self.n_actions)\n",
    "        avg_lift = np.mean(lifts)\n",
    "\n",
    "        sn_umg = self._SN_UMG_GH([record for records in set_of_records for record in records], n_action=self.n_actions)[0]\n",
    "\n",
    "        print(f'Train SN-UMG: {round(sn_umg, 4)}')\n",
    "\n",
    "        for X, y, treat, actions, lift in zip(epoch_features, epoch_ys, epoch_treats, epoch_actions, lifts):\n",
    "            rewards = np.zeros(len(X))\n",
    "            for a in range(self.n_actions):\n",
    "                a_control = action_control[a]\n",
    "\n",
    "                marker = ((actions == a) & (actions == treat)).astype(np.int16)\n",
    "                rewards += marker * ((y - a_control) + lift - avg_lift)\n",
    "                marker = ((treat == 0) & (actions == a) & (a > 0)).astype(np.int16)\n",
    "                rewards += marker * (-(y - a_control) + lift - avg_lift)\n",
    "            epoch_rewards.append(torch.Tensor(rewards))\n",
    "\n",
    "        self.model.train()\n",
    "        for X, actions, rewards in zip(epoch_features, epoch_actions, epoch_rewards):\n",
    "            bs = X.size(0)\n",
    "            X = X.to(device)\n",
    "            logits = self.model(X)\n",
    "            probs = torch.softmax(logits, dim=-1)\n",
    "            entropy = (-probs * torch.log(probs)).sum(-1).mean()\n",
    "\n",
    "            minus_log_prob = -torch.log(probs[torch.arange(bs), actions])\n",
    "            entropy = (torch.log(probs) * probs).mean(1)\n",
    "            loss = (minus_log_prob * rewards + entropy).mean()\n",
    "\n",
    "            self.optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            self.optimizer.step()\n",
    "    \n",
    "    def validate(self):\n",
    "        preds = []\n",
    "        ys = []\n",
    "        treats = []\n",
    "\n",
    "        records = []\n",
    "\n",
    "        self.model.eval()\n",
    "        with torch.no_grad():\n",
    "            for X, y, treat in self.val_loader:\n",
    "                logits = self.model(X)\n",
    "                probs = torch.softmax(logits, 1)\n",
    "                actions = torch.argmax(logits, 1).cpu().numpy()\n",
    "\n",
    "                treat = treat.cpu().numpy()\n",
    "                y = y.cpu().numpy()\n",
    "\n",
    "                preds.extend(probs[:, 1].cpu().numpy())\n",
    "                ys.extend(y)\n",
    "                treats.extend(treat)\n",
    "\n",
    "                batch_records = list(zip(actions, treat, y))\n",
    "                records.extend(batch_records)\n",
    "        \n",
    "        sn_umg = self._SN_UMG_GH(records, self.n_actions)[0]\n",
    "\n",
    "        print(f'Val SN-UMG: {round(sn_umg, 4)}\\n')\n",
    "\n",
    "        return sn_umg\n",
    "    \n",
    "    def train(self):\n",
    "        best_score = 0\n",
    "        best_params = None\n",
    "\n",
    "        for epoch in range(self.train_config.epochs):\n",
    "            print(f'Epoch #{epoch + 1}:')\n",
    "            self._train_epoch()\n",
    "            score = self.validate()\n",
    "            if score > best_score:\n",
    "                best_score = score\n",
    "                best_params = copy.deepcopy(self.model.state_dict())\n",
    "        \n",
    "        self.model.load_state_dict(best_params)\n",
    "\n",
    "    def test(self):\n",
    "        preds = []\n",
    "        ys = []\n",
    "        treats = []\n",
    "\n",
    "        records = []\n",
    "\n",
    "        self.model.eval()\n",
    "        with torch.no_grad():\n",
    "            for X, y, treat in self.test_loader:\n",
    "                logits = self.model(X)\n",
    "                probs = torch.softmax(logits, 1)\n",
    "                actions = torch.argmax(logits, 1).cpu().numpy()\n",
    "\n",
    "                treat = treat.cpu().numpy()\n",
    "                y = y.cpu().numpy()\n",
    "\n",
    "                preds.extend(probs[:, 1].cpu().numpy())\n",
    "                ys.extend(y)\n",
    "                treats.extend(treat)\n",
    "\n",
    "                batch_records = list(zip(actions, treat, y))\n",
    "                records.extend(batch_records)\n",
    "        \n",
    "        sn_umg = self._SN_UMG_GH(records, self.n_actions)[0]\n",
    "\n",
    "        print(f'\\nTest SN-UMG: {round(sn_umg, 4)}')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "y0sg9NRLybEb"
   },
   "outputs": [],
   "source": [
    "class TrainConfig:\n",
    "    epochs = 100\n",
    "    lr = 1e-3\n",
    "    batch_size = 2000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-e_H5Y-5v2Sn"
   },
   "outputs": [],
   "source": [
    "torch.manual_seed(38)\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "model = PolicyGradient(2, 8, [20, 15, 5])\n",
    "trainer = Trainer(model, \n",
    "                                    action_probs, \n",
    "                                    X5Dataset(X_train, y_train, treat_train), \n",
    "                                    X5Dataset(X_val, y_val, treat_val),\n",
    "                                    X5Dataset(X_test, y_test, treat_test),\n",
    "                                    TrainConfig(), \n",
    "                                    device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "S78JdC9aH4MR",
    "outputId": "d1b4d7f2-6097-45a2-dc4e-bcea147e6a1a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #1:\n",
      "Train SN-UMG: 0.7279\n",
      "Val SN-UMG: 0.6979\n",
      "\n",
      "Epoch #2:\n",
      "Train SN-UMG: 0.6842\n",
      "Val SN-UMG: 0.6937\n",
      "\n",
      "Epoch #3:\n",
      "Train SN-UMG: 0.7385\n",
      "Val SN-UMG: 0.7007\n",
      "\n",
      "Epoch #4:\n",
      "Train SN-UMG: 0.694\n",
      "Val SN-UMG: 0.7148\n",
      "\n",
      "Epoch #5:\n",
      "Train SN-UMG: 0.6506\n",
      "Val SN-UMG: 0.7134\n",
      "\n",
      "Epoch #6:\n",
      "Train SN-UMG: 0.7484\n",
      "Val SN-UMG: 0.7252\n",
      "\n",
      "Epoch #7:\n",
      "Train SN-UMG: 0.6965\n",
      "Val SN-UMG: 0.7215\n",
      "\n",
      "Epoch #8:\n",
      "Train SN-UMG: 0.7895\n",
      "Val SN-UMG: 0.7217\n",
      "\n",
      "Epoch #9:\n",
      "Train SN-UMG: 0.7104\n",
      "Val SN-UMG: 0.7288\n",
      "\n",
      "Epoch #10:\n",
      "Train SN-UMG: 0.6924\n",
      "Val SN-UMG: 0.7303\n",
      "\n",
      "Epoch #11:\n",
      "Train SN-UMG: 0.6876\n",
      "Val SN-UMG: 0.7352\n",
      "\n",
      "Epoch #12:\n",
      "Train SN-UMG: 0.8148\n",
      "Val SN-UMG: 0.7328\n",
      "\n",
      "Epoch #13:\n",
      "Train SN-UMG: 0.8345\n",
      "Val SN-UMG: 0.7304\n",
      "\n",
      "Epoch #14:\n",
      "Train SN-UMG: 0.7439\n",
      "Val SN-UMG: 0.7409\n",
      "\n",
      "Epoch #15:\n",
      "Train SN-UMG: 0.7014\n",
      "Val SN-UMG: 0.7538\n",
      "\n",
      "Epoch #16:\n",
      "Train SN-UMG: 0.6514\n",
      "Val SN-UMG: 0.7537\n",
      "\n",
      "Epoch #17:\n",
      "Train SN-UMG: 0.6994\n",
      "Val SN-UMG: 0.7543\n",
      "\n",
      "Epoch #18:\n",
      "Train SN-UMG: 0.8015\n",
      "Val SN-UMG: 0.7584\n",
      "\n",
      "Epoch #19:\n",
      "Train SN-UMG: 0.8251\n",
      "Val SN-UMG: 0.76\n",
      "\n",
      "Epoch #20:\n",
      "Train SN-UMG: 0.753\n",
      "Val SN-UMG: 0.7648\n",
      "\n",
      "Epoch #21:\n",
      "Train SN-UMG: 0.7697\n",
      "Val SN-UMG: 0.769\n",
      "\n",
      "Epoch #22:\n",
      "Train SN-UMG: 0.7287\n",
      "Val SN-UMG: 0.7712\n",
      "\n",
      "Epoch #23:\n",
      "Train SN-UMG: 0.7213\n",
      "Val SN-UMG: 0.7722\n",
      "\n",
      "Epoch #24:\n",
      "Train SN-UMG: 0.774\n",
      "Val SN-UMG: 0.7732\n",
      "\n",
      "Epoch #25:\n",
      "Train SN-UMG: 0.7939\n",
      "Val SN-UMG: 0.767\n",
      "\n",
      "Epoch #26:\n",
      "Train SN-UMG: 0.7904\n",
      "Val SN-UMG: 0.7646\n",
      "\n",
      "Epoch #27:\n",
      "Train SN-UMG: 0.7394\n",
      "Val SN-UMG: 0.7661\n",
      "\n",
      "Epoch #28:\n",
      "Train SN-UMG: 0.7799\n",
      "Val SN-UMG: 0.7662\n",
      "\n",
      "Epoch #29:\n",
      "Train SN-UMG: 0.7415\n",
      "Val SN-UMG: 0.7628\n",
      "\n",
      "Epoch #30:\n",
      "Train SN-UMG: 0.8116\n",
      "Val SN-UMG: 0.7621\n",
      "\n",
      "Epoch #31:\n",
      "Train SN-UMG: 0.8443\n",
      "Val SN-UMG: 0.7614\n",
      "\n",
      "Epoch #32:\n",
      "Train SN-UMG: 0.8024\n",
      "Val SN-UMG: 0.7611\n",
      "\n",
      "Epoch #33:\n",
      "Train SN-UMG: 0.9032\n",
      "Val SN-UMG: 0.7616\n",
      "\n",
      "Epoch #34:\n",
      "Train SN-UMG: 0.8795\n",
      "Val SN-UMG: 0.7606\n",
      "\n",
      "Epoch #35:\n",
      "Train SN-UMG: 0.8379\n",
      "Val SN-UMG: 0.755\n",
      "\n",
      "Epoch #36:\n",
      "Train SN-UMG: 0.7414\n",
      "Val SN-UMG: 0.7559\n",
      "\n",
      "Epoch #37:\n",
      "Train SN-UMG: 0.7747\n",
      "Val SN-UMG: 0.7569\n",
      "\n",
      "Epoch #38:\n",
      "Train SN-UMG: 0.8012\n",
      "Val SN-UMG: 0.7557\n",
      "\n",
      "Epoch #39:\n",
      "Train SN-UMG: 0.7543\n",
      "Val SN-UMG: 0.7553\n",
      "\n",
      "Epoch #40:\n",
      "Train SN-UMG: 0.7599\n",
      "Val SN-UMG: 0.7557\n",
      "\n",
      "Epoch #41:\n",
      "Train SN-UMG: 0.8467\n",
      "Val SN-UMG: 0.7548\n",
      "\n",
      "Epoch #42:\n",
      "Train SN-UMG: 0.8366\n",
      "Val SN-UMG: 0.7522\n",
      "\n",
      "Epoch #43:\n",
      "Train SN-UMG: 0.8446\n",
      "Val SN-UMG: 0.7517\n",
      "\n",
      "Epoch #44:\n",
      "Train SN-UMG: 0.7788\n",
      "Val SN-UMG: 0.7497\n",
      "\n",
      "Epoch #45:\n",
      "Train SN-UMG: 0.8506\n",
      "Val SN-UMG: 0.7508\n",
      "\n",
      "Epoch #46:\n",
      "Train SN-UMG: 0.7891\n",
      "Val SN-UMG: 0.7555\n",
      "\n",
      "Epoch #47:\n",
      "Train SN-UMG: 0.8027\n",
      "Val SN-UMG: 0.7593\n",
      "\n",
      "Epoch #48:\n",
      "Train SN-UMG: 0.7692\n",
      "Val SN-UMG: 0.7662\n",
      "\n",
      "Epoch #49:\n",
      "Train SN-UMG: 0.7909\n",
      "Val SN-UMG: 0.7662\n",
      "\n",
      "Epoch #50:\n",
      "Train SN-UMG: 0.7619\n",
      "Val SN-UMG: 0.7641\n",
      "\n",
      "Epoch #51:\n",
      "Train SN-UMG: 0.8816\n",
      "Val SN-UMG: 0.7656\n",
      "\n",
      "Epoch #52:\n",
      "Train SN-UMG: 0.7722\n",
      "Val SN-UMG: 0.7675\n",
      "\n",
      "Epoch #53:\n",
      "Train SN-UMG: 0.8875\n",
      "Val SN-UMG: 0.766\n",
      "\n",
      "Epoch #54:\n",
      "Train SN-UMG: 0.7922\n",
      "Val SN-UMG: 0.7676\n",
      "\n",
      "Epoch #55:\n",
      "Train SN-UMG: 0.8757\n",
      "Val SN-UMG: 0.7661\n",
      "\n",
      "Epoch #56:\n",
      "Train SN-UMG: 0.8477\n",
      "Val SN-UMG: 0.7696\n",
      "\n",
      "Epoch #57:\n",
      "Train SN-UMG: 0.8315\n",
      "Val SN-UMG: 0.7687\n",
      "\n",
      "Epoch #58:\n",
      "Train SN-UMG: 0.7388\n",
      "Val SN-UMG: 0.7746\n",
      "\n",
      "Epoch #59:\n",
      "Train SN-UMG: 0.8232\n",
      "Val SN-UMG: 0.7722\n",
      "\n",
      "Epoch #60:\n",
      "Train SN-UMG: 0.8224\n",
      "Val SN-UMG: 0.7702\n",
      "\n",
      "Epoch #61:\n",
      "Train SN-UMG: 0.776\n",
      "Val SN-UMG: 0.7725\n",
      "\n",
      "Epoch #62:\n",
      "Train SN-UMG: 0.8136\n",
      "Val SN-UMG: 0.7756\n",
      "\n",
      "Epoch #63:\n",
      "Train SN-UMG: 0.8357\n",
      "Val SN-UMG: 0.7721\n",
      "\n",
      "Epoch #64:\n",
      "Train SN-UMG: 0.8653\n",
      "Val SN-UMG: 0.7689\n",
      "\n",
      "Epoch #65:\n",
      "Train SN-UMG: 0.8763\n",
      "Val SN-UMG: 0.7715\n",
      "\n",
      "Epoch #66:\n",
      "Train SN-UMG: 0.7891\n",
      "Val SN-UMG: 0.772\n",
      "\n",
      "Epoch #67:\n",
      "Train SN-UMG: 0.8772\n",
      "Val SN-UMG: 0.7725\n",
      "\n",
      "Epoch #68:\n",
      "Train SN-UMG: 0.8423\n",
      "Val SN-UMG: 0.7768\n",
      "\n",
      "Epoch #69:\n",
      "Train SN-UMG: 0.7818\n",
      "Val SN-UMG: 0.7759\n",
      "\n",
      "Epoch #70:\n",
      "Train SN-UMG: 0.7175\n",
      "Val SN-UMG: 0.7764\n",
      "\n",
      "Epoch #71:\n",
      "Train SN-UMG: 0.754\n",
      "Val SN-UMG: 0.7754\n",
      "\n",
      "Epoch #72:\n",
      "Train SN-UMG: 0.7405\n",
      "Val SN-UMG: 0.7779\n",
      "\n",
      "Epoch #73:\n",
      "Train SN-UMG: 0.8118\n",
      "Val SN-UMG: 0.7774\n",
      "\n",
      "Epoch #74:\n",
      "Train SN-UMG: 0.8687\n",
      "Val SN-UMG: 0.7784\n",
      "\n",
      "Epoch #75:\n",
      "Train SN-UMG: 0.813\n",
      "Val SN-UMG: 0.7804\n",
      "\n",
      "Epoch #76:\n",
      "Train SN-UMG: 0.8469\n",
      "Val SN-UMG: 0.7819\n",
      "\n",
      "Epoch #77:\n",
      "Train SN-UMG: 0.8237\n",
      "Val SN-UMG: 0.7824\n",
      "\n",
      "Epoch #78:\n",
      "Train SN-UMG: 0.7756\n",
      "Val SN-UMG: 0.7825\n",
      "\n",
      "Epoch #79:\n",
      "Train SN-UMG: 0.7947\n",
      "Val SN-UMG: 0.7825\n",
      "\n",
      "Epoch #80:\n",
      "Train SN-UMG: 0.7979\n",
      "Val SN-UMG: 0.782\n",
      "\n",
      "Epoch #81:\n",
      "Train SN-UMG: 0.7317\n",
      "Val SN-UMG: 0.7836\n",
      "\n",
      "Epoch #82:\n",
      "Train SN-UMG: 0.8791\n",
      "Val SN-UMG: 0.7791\n",
      "\n",
      "Epoch #83:\n",
      "Train SN-UMG: 0.9484\n",
      "Val SN-UMG: 0.7796\n",
      "\n",
      "Epoch #84:\n",
      "Train SN-UMG: 0.7809\n",
      "Val SN-UMG: 0.7772\n",
      "\n",
      "Epoch #85:\n",
      "Train SN-UMG: 0.7517\n",
      "Val SN-UMG: 0.7772\n",
      "\n",
      "Epoch #86:\n",
      "Train SN-UMG: 0.8748\n",
      "Val SN-UMG: 0.7763\n",
      "\n",
      "Epoch #87:\n",
      "Train SN-UMG: 0.8121\n",
      "Val SN-UMG: 0.7773\n",
      "\n",
      "Epoch #88:\n",
      "Train SN-UMG: 0.8346\n",
      "Val SN-UMG: 0.7724\n",
      "\n",
      "Epoch #89:\n",
      "Train SN-UMG: 0.7995\n",
      "Val SN-UMG: 0.7725\n",
      "\n",
      "Epoch #90:\n",
      "Train SN-UMG: 0.8099\n",
      "Val SN-UMG: 0.7734\n",
      "\n",
      "Epoch #91:\n",
      "Train SN-UMG: 0.8692\n",
      "Val SN-UMG: 0.772\n",
      "\n",
      "Epoch #92:\n",
      "Train SN-UMG: 0.7936\n",
      "Val SN-UMG: 0.772\n",
      "\n",
      "Epoch #93:\n",
      "Train SN-UMG: 0.8704\n",
      "Val SN-UMG: 0.7715\n",
      "\n",
      "Epoch #94:\n",
      "Train SN-UMG: 0.8194\n",
      "Val SN-UMG: 0.7724\n",
      "\n",
      "Epoch #95:\n",
      "Train SN-UMG: 0.7923\n",
      "Val SN-UMG: 0.769\n",
      "\n",
      "Epoch #96:\n",
      "Train SN-UMG: 0.8281\n",
      "Val SN-UMG: 0.7719\n",
      "\n",
      "Epoch #97:\n",
      "Train SN-UMG: 0.8358\n",
      "Val SN-UMG: 0.7714\n",
      "\n",
      "Epoch #98:\n",
      "Train SN-UMG: 0.8369\n",
      "Val SN-UMG: 0.7735\n",
      "\n",
      "Epoch #99:\n",
      "Train SN-UMG: 0.8557\n",
      "Val SN-UMG: 0.773\n",
      "\n",
      "Epoch #100:\n",
      "Train SN-UMG: 0.7284\n",
      "Val SN-UMG: 0.7746\n",
      "\n",
      "\n",
      "Test SN-UMG: 0.8338\n"
     ]
    }
   ],
   "source": [
    "trainer.train()\n",
    "trainer.test()"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "RLift.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
