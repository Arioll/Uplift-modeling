{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "australian-custody",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pprint import pprint\n",
    "\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklift.metrics import uplift_at_k\n",
    "from sklift.viz import plot_uplift_curve\n",
    "from sklift.viz import plot_qini_curve\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "import sklearn\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "expensive-uzbekistan",
   "metadata": {},
   "outputs": [],
   "source": [
    "import statsmodels.api as sm\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "from causalml.inference.tree import UpliftRandomForestClassifier\n",
    "from causalml.dataset import *\n",
    "\n",
    "plt.style.use('fivethirtyeight')\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "every-substitute",
   "metadata": {},
   "source": [
    "# Preprocessing Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "minimal-border",
   "metadata": {},
   "outputs": [],
   "source": [
    "Datasets = []"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "infrared-suicide",
   "metadata": {},
   "source": [
    "## X5 Retail Hero Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "nominated-wrong",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_clients = pd.read_csv('data/clients.csv', index_col='client_id')\n",
    "df_train = pd.read_csv('data/uplift_train.csv', index_col='client_id')\n",
    "df_test = pd.read_csv('data/uplift_test.csv', index_col='client_id')\n",
    "\n",
    "df_features = df_clients.copy()\n",
    "df_features['first_issue_time'] = \\\n",
    "    (pd.to_datetime(df_features['first_issue_date'])\n",
    "     - pd.to_datetime(df_features['first_issue_date']).min()) / pd.Timedelta('365d')\n",
    "\n",
    "df_features['first_redeem_time'] = \\\n",
    "    (pd.to_datetime(df_features['first_redeem_date'])\n",
    "     - pd.to_datetime(df_features['first_redeem_date']).min()) / pd.Timedelta('365d')\n",
    "\n",
    "df_features['issue_redeem_delay'] = df_features['first_redeem_time'] \\\n",
    "    - df_features['first_issue_time']\n",
    "\n",
    "df_features = df_features.join(pd.get_dummies(df_features['gender']))\n",
    "df_features['first_redeem_time'] = df_features['first_redeem_time'].fillna(df_features['first_redeem_time'].mean())\n",
    "df_features['issue_redeem_delay'] = df_features['issue_redeem_delay'].fillna(df_features['issue_redeem_delay'].mean())\n",
    "\n",
    "df_features = df_features.drop(['first_issue_date', 'first_redeem_date', 'gender'], axis=1)\n",
    "\n",
    "indices_train = df_train.index\n",
    "indices_test = df_test.index\n",
    "indices_learn, indices_testid = train_test_split(df_train.index, test_size=0.3, random_state=123)\n",
    "\n",
    "X_train = df_features.loc[indices_learn, :]\n",
    "y_train = df_train.loc[indices_learn, 'target']\n",
    "treat_train = df_train.loc[indices_learn, 'treatment_flg']\n",
    "\n",
    "X_test = df_features.loc[indices_testid, :]\n",
    "y_test = df_train.loc[indices_testid, 'target']\n",
    "treat_test =  df_train.loc[indices_testid, 'treatment_flg']\n",
    "\n",
    "X_train_full = df_features.loc[indices_train, :]\n",
    "y_train_full = df_train.loc[:, 'target']\n",
    "treat_train_full = df_train.loc[:, 'treatment_flg']\n",
    "\n",
    "cat_features = ['gender']\n",
    "\n",
    "Datasets.append((X_train, treat_train, y_train, X_test, treat_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "liked-shade",
   "metadata": {},
   "source": [
    "## Hillstrom Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "simplified-cedar",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('data/Hillstrom.csv')\n",
    "df.drop(['history_segment', \"conversion\", \"spend\"], axis=1, inplace=True)\n",
    "\n",
    "cat_cols = ['zip_code', 'channel']\n",
    "df_ohe = pd.get_dummies(df, columns=cat_cols)\n",
    "df_ohe.segment = df_ohe.segment.map({'Womens E-Mail': 1, 'Mens E-Mail': 1, 'No E-Mail': 0})\n",
    "\n",
    "X = df_ohe.drop('visit', axis=1)\n",
    "y = df_ohe['visit'].astype('int')\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=0)\n",
    "\n",
    "treat_train = X_train['segment']\n",
    "treat_test = X_test['segment']\n",
    "\n",
    "X_train.drop(['segment'], axis=1, inplace=True)\n",
    "X_test.drop(['segment'], axis=1, inplace=True)\n",
    "\n",
    "Datasets.append((X_train, treat_train, y_train, X_test, treat_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "posted-gardening",
   "metadata": {},
   "source": [
    "## Kuusito Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "alpine-peeing",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('data/Kuusito.csv')\n",
    "df.drop(['customer_type'], axis=1, inplace=True)\n",
    "\n",
    "df = df.replace(r'Value', '', regex=True)\n",
    "df['target_control'] = df['target_control'].map({'control': 1, 'target': 0})\n",
    "df['outcome'] = df['outcome'].map({'negative': 0, 'positive': 1})\n",
    "\n",
    "df = pd.get_dummies(df,drop_first=True)\n",
    "\n",
    "X = df.drop('outcome', axis=1).astype('int64')\n",
    "y = df['outcome']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=0)\n",
    "\n",
    "treat_train = X_train['target_control']\n",
    "treat_test = X_test['target_control']\n",
    "\n",
    "X_train.drop(['target_control'], axis=1, inplace=True)\n",
    "X_test.drop(['target_control'], axis=1, inplace=True)\n",
    "X_train.drop(['customer_id'], axis=1, inplace=True)\n",
    "X_test.drop(['customer_id'], axis=1, inplace=True)\n",
    "\n",
    "Datasets.append((X_train, treat_train, y_train, X_test, treat_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "wicked-tract",
   "metadata": {},
   "source": [
    "## Synthetic Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "naval-poverty",
   "metadata": {},
   "outputs": [],
   "source": [
    "y, X, treatment, tau, b, e = synthetic_data(mode=2, n=10000, p=8, sigma=1.0)\n",
    "y = (y > np.median(y)).astype(int)\n",
    "X_train, X_test, y_train, y_test, treat_train, treat_test= train_test_split(X, y, treatment, test_size=0.33, random_state=0)\n",
    "\n",
    "X_train = pd.DataFrame(X_train)\n",
    "X_test = pd.DataFrame(X_test)\n",
    "y_train = pd.Series(y_train)\n",
    "y_test = pd.Series(y_test)\n",
    "treat_train = pd.Series(treat_train)\n",
    "treat_test = pd.Series(treat_test)\n",
    "\n",
    "Datasets.append((X_train, treat_train, y_train, X_test, treat_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fabulous-treatment",
   "metadata": {},
   "source": [
    "# Preparing Evaluation Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "intimate-pursuit",
   "metadata": {},
   "outputs": [],
   "source": [
    "Functions = ['KL', 'ED', 'Chi']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "twelve-slope",
   "metadata": {},
   "source": [
    "# UpliftRandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "driving-seller",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rf_score(data, eval_func):\n",
    "    (X_train, treat_train, y_train, X_test, treat_test, y_test) = data\n",
    "    \n",
    "    rf_clf = UpliftRandomForestClassifier(n_estimators=100, control_name='0', evaluationFunction=eval_func)\n",
    "\n",
    "    rf_clf.fit(X_train.values,\n",
    "               treatment=treat_train.map(str).values,\n",
    "               y=y_train.values)\n",
    "\n",
    "    y_pred = rf_clf.predict(X_test.values).reshape(-1)\n",
    "    score = uplift_at_k(y_true=y_test, uplift=y_pred, treatment=treat_test, strategy='by_group', k=0.3)\n",
    "    return round(score, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "radical-husband",
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = np.zeros((4, 3))\n",
    "\n",
    "for di, data in enumerate(Datasets):\n",
    "    for fi, eval_func in enumerate(Functions):\n",
    "        scores[di, fi] = rf_score(data, eval_func)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "sharp-illness",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>KL</th>\n",
       "      <th>ED</th>\n",
       "      <th>Chi</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Dataset</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>RetailHero</th>\n",
       "      <td>0.059</td>\n",
       "      <td>0.059</td>\n",
       "      <td>0.053</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Hillstrom</th>\n",
       "      <td>0.067</td>\n",
       "      <td>0.073</td>\n",
       "      <td>0.064</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Kuusito</th>\n",
       "      <td>0.145</td>\n",
       "      <td>0.147</td>\n",
       "      <td>0.151</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Synthetic</th>\n",
       "      <td>0.388</td>\n",
       "      <td>0.378</td>\n",
       "      <td>0.373</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               KL     ED    Chi\n",
       "Dataset                        \n",
       "RetailHero  0.059  0.059  0.053\n",
       "Hillstrom   0.067  0.073  0.064\n",
       "Kuusito     0.145  0.147  0.151\n",
       "Synthetic   0.388  0.378  0.373"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df = pd.DataFrame(scores,\n",
    "                  columns=Functions,\n",
    "                  index=['RetailHero', 'Hillstrom', 'Kuusito', 'Synthetic'])\n",
    "\n",
    "df.index.name = 'Dataset'\n",
    "display(df)\n",
    "\n",
    "with open(\"ForestByFunctions.txt\", \"w\") as text_file:\n",
    "    text_file.write(df.to_latex())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7 (tensorflow)",
   "language": "python",
   "name": "tensorflow"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
