{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pprint import pprint\n",
    "\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklift.metrics import uplift_at_k\n",
    "from sklift.viz import plot_uplift_curve\n",
    "from sklift.viz import plot_qini_curve\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from causalml.inference.meta import BaseXRegressor, BaseTClassifier, BaseSClassifier, BaseRClassifier\n",
    "from causalml.dataset import *\n",
    "from causalml.metrics import *\n",
    "\n",
    "from classifierNN import *\n",
    "from lightgbm import LGBMClassifier\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import random\n",
    "seed = 42"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MetaLearners based on neural network\n",
    "\n",
    "***Classifier_NN*** is class that trains neural network that consists of fully connected layers (k-1 Linear layes with BatchNorm and LeakyRElu(0.05) and last Lenear layer with Sigmoid). Number of layers (k) is defined by length of list ***hid_size***. Also, we can define number of ***epoch*** and learning rate (***lr***). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "def MetaLearners_NN(X_train,treat_train,y_train,X_val,treat_val,y_val,hid_size,epoch = 5, lr=1e-3):\n",
    "    torch.manual_seed(seed)\n",
    "    \n",
    "    learner_t = BaseTClassifier(learner=Classifier_NN(X_train.shape[1],hid_size,epoch,lr))\n",
    "    learner_t.fit(X=X_train, treatment=treat_train, y=y_train)\n",
    "    cate_t = np.squeeze(learner_t.predict(X_val))\n",
    "    score_t = uplift_at_k(y_true=y_val, uplift=cate_t, treatment=treat_val, strategy='by_group', k=0.3)\n",
    "    \n",
    "    learner_s = BaseSClassifier(learner=Classifier_NN(X_train.shape[1]+1,hid_size,epoch,lr))\n",
    "    learner_s.fit(X=X_train, treatment=treat_train, y=y_train)\n",
    "    cate_s = np.squeeze(learner_s.predict(X_val))\n",
    "    score_s = uplift_at_k(y_true=y_val, uplift=cate_s, treatment=treat_val, strategy='by_group', k=0.3)\n",
    "    \n",
    "    learner_x = BaseXRegressor(Classifier_NN(X_train.shape[1],hid_size,epoch,lr),Classifier_NN(X_train.shape[1],hid_size,epoch,lr))\n",
    "    learner_x.fit(X=X_train, treatment=treat_train, y=y_train)\n",
    "    cate_x = np.squeeze(learner_x.predict(X_val))\n",
    "    score_x = uplift_at_k(y_true=y_val, uplift=cate_x, treatment=treat_val, strategy='by_group', k=0.3)\n",
    "    \n",
    "    return score_t, score_s, score_x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MetaLearners based on LGBMClassifier\n",
    "Light GBM Classifier (***LGBMClassifier***) is a fast, distributed, high-performance gradient boosting framework based on decision tree algorithm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def MetaLearners(X_train,treat_train,y_train,X_val,treat_val,y_val):\n",
    "    learner_t = BaseTClassifier(learner=LGBMClassifier())\n",
    "    learner_t.fit(X=X_train, treatment=treat_train, y=y_train)\n",
    "    cate_t = np.squeeze(learner_t.predict(X_val))\n",
    "    score_t = uplift_at_k(y_true=y_val, uplift=cate_t, treatment=treat_val, strategy='by_group', k=0.3)\n",
    "    \n",
    "    learner_s = BaseSClassifier(learner=LGBMClassifier())\n",
    "    learner_s.fit(X=X_train, treatment=treat_train, y=y_train)\n",
    "    cate_s = np.squeeze(learner_s.predict(X_val))\n",
    "    score_s = uplift_at_k(y_true=y_val, uplift=cate_s, treatment=treat_val, strategy='by_group', k=0.3)\n",
    "    \n",
    "    learner_x = BaseXRegressor(LGBMClassifier(),LGBMClassifier())\n",
    "    learner_x.fit(X=X_train, treatment=treat_train, y=y_train)\n",
    "    cate_x = np.squeeze(learner_x.predict(X_val))\n",
    "    score_x = uplift_at_k(y_true=y_val, uplift=cate_x, treatment=treat_val, strategy='by_group', k=0.3)\n",
    " \n",
    "    return score_t, score_s, score_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "met = np.array(['T','S','X'])[:,None]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# X5 Retail Hero dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_clients = pd.read_csv('clients.csv', index_col='client_id')\n",
    "df_train = pd.read_csv('uplift_train.csv', index_col='client_id')\n",
    "df_test = pd.read_csv('uplift_test.csv', index_col='client_id')\n",
    "\n",
    "df_features = df_clients.copy()\n",
    "df_features['first_issue_time'] = \\\n",
    "    (pd.to_datetime(df_features['first_issue_date'])\n",
    "     - pd.to_datetime(df_features['first_issue_date']).min()) / pd.Timedelta('365d')\n",
    "\n",
    "df_features['first_redeem_time'] = \\\n",
    "    (pd.to_datetime(df_features['first_redeem_date'])\n",
    "     - pd.to_datetime(df_features['first_redeem_date']).min()) / pd.Timedelta('365d')\n",
    "\n",
    "df_features['issue_redeem_delay'] = df_features['first_redeem_time'] \\\n",
    "    - df_features['first_issue_time']\n",
    "\n",
    "df_features = df_features.join(pd.get_dummies(df_features['gender']))\n",
    "df_features['first_redeem_time'] = df_features['first_redeem_time'].fillna(df_features['first_redeem_time'].mean())\n",
    "df_features['issue_redeem_delay'] = df_features['issue_redeem_delay'].fillna(df_features['issue_redeem_delay'].mean())\n",
    "\n",
    "df_features = df_features.drop(['first_issue_date', 'first_redeem_date', 'gender'], axis=1)\n",
    "\n",
    "indices_train = df_train.index\n",
    "indices_test = df_test.index\n",
    "indices_learn, indices_valid = train_test_split(df_train.index, test_size=0.3, random_state=123)\n",
    "\n",
    "X_train = df_features.loc[indices_learn, :]\n",
    "y_train = df_train.loc[indices_learn, 'target']\n",
    "treat_train = df_train.loc[indices_learn, 'treatment_flg']\n",
    "\n",
    "X_val = df_features.loc[indices_valid, :]\n",
    "y_val = df_train.loc[indices_valid, 'target']\n",
    "treat_val =  df_train.loc[indices_valid, 'treatment_flg']\n",
    "\n",
    "X_train_full = df_features.loc[indices_train, :]\n",
    "y_train_full = df_train.loc[:, 'target']\n",
    "treat_train_full = df_train.loc[:, 'treatment_flg']\n",
    "\n",
    "X_test = df_features.loc[indices_test, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "res_x5 = np.array(['X5 Retail Hero']*3)[:,None]\n",
    "res = np.array(MetaLearners(X_train.values,treat_train,y_train,X_val.values,treat_val,y_val))[:,None]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 4 , result (0.028327895102571055, 0.03497839813891668, 0.038607032438039424)\n",
      "Epoch: 5 , result (0.05034391774172431, 0.03815699366546821, 0.03838610431332268)\n",
      "Epoch: 6 , result (0.03204590773135141, 0.03957068189371282, 0.0381620290643222)\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(seed)\n",
    "res_nn = []\n",
    "sum_res_nn = []\n",
    "for epoch in [4,5,6]:\n",
    "    res_nn.append(MetaLearners_NN(X_train.values,treat_train,y_train,X_val.values,treat_val,y_val,[5,3],epoch))\n",
    "    sum_res_nn.append(sum(res_nn[-1]))\n",
    "    print('Epoch:', epoch, ', result', res_nn[-1])\n",
    "    \n",
    "res_NN = np.array(res_nn[np.array(sum_res_nn).argmax()])[:,None]\n",
    "res_x5 = np.concatenate((res_x5,met,np.round(res,3),np.round(res_NN,3)),axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Dataset</th>\n",
       "      <th>Learner</th>\n",
       "      <th>LGBMClassifier</th>\n",
       "      <th>MLP</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>X5 Retail Hero</td>\n",
       "      <td>T</td>\n",
       "      <td>0.053</td>\n",
       "      <td>0.05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>X5 Retail Hero</td>\n",
       "      <td>S</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.038</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>X5 Retail Hero</td>\n",
       "      <td>X</td>\n",
       "      <td>0.038</td>\n",
       "      <td>0.038</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Dataset Learner LGBMClassifier    MLP\n",
       "0  X5 Retail Hero       T          0.053   0.05\n",
       "1  X5 Retail Hero       S           0.04  0.038\n",
       "2  X5 Retail Hero       X          0.038  0.038"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(res_x5, columns=['Dataset','Learner','LGBMClassifier', 'MLP'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hillstrom dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('Hillstrom.csv')\n",
    "df.drop(['history_segment', \"conversion\", \"spend\"], axis=1, inplace=True)\n",
    "\n",
    "cat_cols = ['zip_code', 'channel']\n",
    "df_ohe = pd.get_dummies(df, columns=cat_cols)\n",
    "df_ohe.segment = df_ohe.segment.map({'Womens E-Mail': 1, 'Mens E-Mail': 1, 'No E-Mail': 0})\n",
    "\n",
    "X = df_ohe.drop('visit', axis=1)\n",
    "y = df_ohe['visit'].astype('int')\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=0)\n",
    "\n",
    "treat_train = X_train['segment']\n",
    "treat_test = X_test['segment']\n",
    "\n",
    "X_train.drop(['segment'], axis=1, inplace=True)\n",
    "X_test.drop(['segment'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 4 , result (0.06931773931007518, 0.06227740714827032, 0.0728053796358784)\n",
      "Epoch: 5 , result (0.0743347102005954, 0.07435218504302307, 0.0728053796358784)\n",
      "Epoch: 6 , result (0.059285601383736924, 0.06892551365326349, 0.0728053796358784)\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(seed)\n",
    "res_hill = np.array(['Hillstorm']*3)[:,None]\n",
    "res = np.array(MetaLearners(X_train.values,treat_train,y_train,X_test.values,treat_test,y_test))[:,None]\n",
    "\n",
    "res_nn = []\n",
    "sum_res_nn = []\n",
    "for epoch in [4,5,6]:\n",
    "    res_nn.append(MetaLearners_NN(X_train.values,treat_train,y_train,X_test.values,treat_test,y_test,[8,4],epoch))\n",
    "    sum_res_nn.append(sum(res_nn[-1]))\n",
    "    print('Epoch:', epoch, ', result', res_nn[-1])\n",
    "    \n",
    "res_NN = np.array(res_nn[np.array(sum_res_nn).argmax()])[:,None]\n",
    "res_hill = np.concatenate((res_hill,met,np.round(res,3),np.round(res_NN,3)),axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Dataset</th>\n",
       "      <th>Learner</th>\n",
       "      <th>LGBMClassifier</th>\n",
       "      <th>MLP</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Hillstorm</td>\n",
       "      <td>T</td>\n",
       "      <td>0.061</td>\n",
       "      <td>0.074</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Hillstorm</td>\n",
       "      <td>S</td>\n",
       "      <td>0.067</td>\n",
       "      <td>0.074</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Hillstorm</td>\n",
       "      <td>X</td>\n",
       "      <td>0.073</td>\n",
       "      <td>0.073</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Dataset Learner LGBMClassifier    MLP\n",
       "0  Hillstorm       T          0.061  0.074\n",
       "1  Hillstorm       S          0.067  0.074\n",
       "2  Hillstorm       X          0.073  0.073"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(res_hill, columns=['Dataset','Learner','LGBMClassifier', 'MLP'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Kuusito dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('Kuusito.csv')\n",
    "df.drop(['customer_type'], axis=1, inplace=True)\n",
    "\n",
    "df = df.replace(r'Value', '', regex=True)\n",
    "df['target_control'] = df['target_control'].map({'control': 1, 'target': 0})\n",
    "df['outcome'] = df['outcome'].map({'negative': 0, 'positive': 1})\n",
    "\n",
    "df = pd.get_dummies(df,drop_first=True)\n",
    "\n",
    "X = df.drop('outcome', axis=1).astype('int64')\n",
    "y = df['outcome']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=0)\n",
    "\n",
    "treat_train = X_train['target_control']\n",
    "treat_test = X_test['target_control']\n",
    "\n",
    "X_train.drop(['target_control'], axis=1, inplace=True)\n",
    "X_test.drop(['target_control'], axis=1, inplace=True)\n",
    "X_train.drop(['customer_id'], axis=1, inplace=True)\n",
    "X_test.drop(['customer_id'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 19 , result (0.15655214723926386, 0.18486707566462168, 0.07351738241308797)\n",
      "Epoch: 20 , result (0.17886707566462168, 0.1864171779141104, 0.09801226993865025)\n",
      "Epoch: 21 , result (0.12223721881390598, 0.1643721881390593, 0.07183231083844582)\n",
      "Epoch: 22 , result (0.12214723926380372, 0.1441022494887525, 0.0656523517382413)\n"
     ]
    }
   ],
   "source": [
    "res_kuusito = np.array(['Kuusito']*3)[:,None]\n",
    "res = np.array(MetaLearners(X_train.values,treat_train,y_train,X_test.values,treat_test,y_test))[:,None]\n",
    "\n",
    "res_nn = []\n",
    "sum_res_nn = []\n",
    "for epoch in [19,20,21,22]:\n",
    "    res_nn.append(MetaLearners_NN(X_train.values,treat_train,y_train,X_test.values,treat_test,y_test,[40,30,20,10],epoch,5e-3))\n",
    "    sum_res_nn.append(sum(res_nn[-1]))\n",
    "    print('Epoch:', epoch, ', result', res_nn[-1])\n",
    "    \n",
    "res_NN = np.array(res_nn[np.array(sum_res_nn).argmax()])[:,None]\n",
    "res_kuusito = np.concatenate((res_kuusito,met,np.round(res,3),np.round(res_NN,3)),axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Dataset</th>\n",
       "      <th>Learner</th>\n",
       "      <th>LGBMClassifier</th>\n",
       "      <th>MLP</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Kuusito</td>\n",
       "      <td>T</td>\n",
       "      <td>0.279</td>\n",
       "      <td>0.179</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Kuusito</td>\n",
       "      <td>S</td>\n",
       "      <td>0.31</td>\n",
       "      <td>0.186</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Kuusito</td>\n",
       "      <td>X</td>\n",
       "      <td>0.239</td>\n",
       "      <td>0.098</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Dataset Learner LGBMClassifier    MLP\n",
       "0  Kuusito       T          0.279  0.179\n",
       "1  Kuusito       S           0.31  0.186\n",
       "2  Kuusito       X          0.239  0.098"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(res_kuusito, columns=['Dataset','Learner','LGBMClassifier', 'MLP'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Synthetic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "y, X, treatment, tau, b, e = synthetic_data(mode=2, n=10000, p=8, sigma=1.0)\n",
    "y = (y > np.median(y)).astype(int)\n",
    "X_train, X_test, y_train, y_test, treat_train, treat_test= train_test_split(X, y, treatment, test_size=0.33, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 10 , result (0.4319376227897839, 0.45512033398821217, 0.18695153896529138)\n",
      "Epoch: 11 , result (0.4253315324165029, 0.42739030779305826, 0.23219138834315656)\n",
      "Epoch: 12 , result (0.43110674525212833, 0.4884127373935822, 0.3528405370006549)\n",
      "Epoch: 13 , result (0.42301080550098236, 0.40693762278978396, 0.2571913883431566)\n",
      "Epoch: 14 , result (0.41896283562540926, 0.4401154223968566, 0.18695153896529138)\n"
     ]
    }
   ],
   "source": [
    "res_syn = np.array(['Synthetic']*3)[:,None]\n",
    "res = np.array(MetaLearners(X_train,treat_train,y_train,X_test,treat_test,y_test))[:,None]\n",
    "res_nn = []\n",
    "sum_res_nn = []\n",
    "for epoch in [10,11,12,13,14]:\n",
    "    res_nn.append(MetaLearners_NN(X_train,treat_train,y_train,X_test,treat_test,y_test,[6,4,2],epoch))\n",
    "    sum_res_nn.append(sum(res_nn[-1]))\n",
    "    print('Epoch:', epoch, ', result', res_nn[-1])\n",
    "    \n",
    "res_NN = np.array(res_nn[np.array(sum_res_nn).argmax()])[:,None]\n",
    "res_syn = np.concatenate((res_syn,met,np.round(res,3),np.round(res_NN,3)),axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Dataset</th>\n",
       "      <th>Learner</th>\n",
       "      <th>LGBMClassifier</th>\n",
       "      <th>MLP</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Synthetic</td>\n",
       "      <td>T</td>\n",
       "      <td>0.42</td>\n",
       "      <td>0.431</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Synthetic</td>\n",
       "      <td>S</td>\n",
       "      <td>0.458</td>\n",
       "      <td>0.488</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Synthetic</td>\n",
       "      <td>X</td>\n",
       "      <td>0.361</td>\n",
       "      <td>0.353</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Dataset Learner LGBMClassifier    MLP\n",
       "0  Synthetic       T           0.42  0.431\n",
       "1  Synthetic       S          0.458  0.488\n",
       "2  Synthetic       X          0.361  0.353"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(res_syn, columns=['Dataset','Learner','LGBMClassifier', 'MLP'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ALL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Dataset</th>\n",
       "      <th>Learner</th>\n",
       "      <th>LGBMClassifier</th>\n",
       "      <th>MLP</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>X5 Retail Hero</td>\n",
       "      <td>T</td>\n",
       "      <td>0.053</td>\n",
       "      <td>0.05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>X5 Retail Hero</td>\n",
       "      <td>S</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.038</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>X5 Retail Hero</td>\n",
       "      <td>X</td>\n",
       "      <td>0.038</td>\n",
       "      <td>0.038</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Hillstorm</td>\n",
       "      <td>T</td>\n",
       "      <td>0.061</td>\n",
       "      <td>0.074</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Hillstorm</td>\n",
       "      <td>S</td>\n",
       "      <td>0.067</td>\n",
       "      <td>0.074</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Hillstorm</td>\n",
       "      <td>X</td>\n",
       "      <td>0.073</td>\n",
       "      <td>0.073</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Kuusito</td>\n",
       "      <td>T</td>\n",
       "      <td>0.279</td>\n",
       "      <td>0.179</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Kuusito</td>\n",
       "      <td>S</td>\n",
       "      <td>0.31</td>\n",
       "      <td>0.186</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Kuusito</td>\n",
       "      <td>X</td>\n",
       "      <td>0.239</td>\n",
       "      <td>0.098</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Synthetic</td>\n",
       "      <td>T</td>\n",
       "      <td>0.42</td>\n",
       "      <td>0.431</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Synthetic</td>\n",
       "      <td>S</td>\n",
       "      <td>0.458</td>\n",
       "      <td>0.488</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Synthetic</td>\n",
       "      <td>X</td>\n",
       "      <td>0.361</td>\n",
       "      <td>0.353</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Dataset Learner LGBMClassifier    MLP\n",
       "0   X5 Retail Hero       T          0.053   0.05\n",
       "1   X5 Retail Hero       S           0.04  0.038\n",
       "2   X5 Retail Hero       X          0.038  0.038\n",
       "3        Hillstorm       T          0.061  0.074\n",
       "4        Hillstorm       S          0.067  0.074\n",
       "5        Hillstorm       X          0.073  0.073\n",
       "6          Kuusito       T          0.279  0.179\n",
       "7          Kuusito       S           0.31  0.186\n",
       "8          Kuusito       X          0.239  0.098\n",
       "9        Synthetic       T           0.42  0.431\n",
       "10       Synthetic       S          0.458  0.488\n",
       "11       Synthetic       X          0.361  0.353"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res_all = np.concatenate((res_x5,res_hill,res_kuusito,res_syn),axis=0)\n",
    "pd.DataFrame(res_all, columns=['Dataset','Learner','LGBMClassifier', 'MLP'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
